---
title: PHONEME-LEVEL BERT FOR ENHANCED PROSODY OF TEXT-TO-SPEECH WITH GRAPHEME PREDICTIONS
tags:
  - paper
  - ML
  - DL
created: 2024-08-12 16:16
---

# PHONEME-LEVEL BERT FOR ENHANCED PROSODY OF TEXT-TO-SPEECH WITH GRAPHEME PREDICTIONS


흥미로운 내용 3가지 :

- 음성 합성을 위해 음소 수준 BERT 모델이 효과적으로 자연스러움을 향상시킨다.
- 음성 합성 모델의 어조와 감정을 포함한 억양을 효과적으로 학습하여 성능을 향상시킬 수 있다.
- 폰음 수준 BERT 모델은 자연스러운 음성을 생성하기 위해 폰음만을 사용하여 성능을 개선시킬 수 있다.


이 논문은 텍스트-음성 변환(TTS) 시스템의 자연스러움과 프로소디를 향상시키기 위해 설계된 음소 수준 BERT(PL-BERT)를 제안합니다. 기존의 언어 모델들이 단어 수준 또는 부분 음소 수준에서 훈련되던 반면, PL-BERT는 음소만 입력으로 사용하여 효율성을 높이고 있습니다. 이 모델은 음소 예측과 그래프 내 예측을 조합하여 사전 훈련을 진행하며, 실험 결과 PL-BERT가 기존의 최첨단 모델보다 자연스러움과 표현력을 높이는 데 크게 기여한다는 것을 보여줍니다.

## 핵심주제

음성 합성을 위한 **음소 수준 BERT** 모델이 제안되었습니다.

- **대규모** 사전 훈련된 언어 모델을 활용한 이 연구는 음소 예측을 통해 음성 합성의 자연스러움을 향상시키려 합니다.
    
- 제안된 음소 수준 BERT(PL-BERT)는 기존 음성 합성 모델들보다 유의미하게 더 나은 **성능**을 보여주었습니다.
    
- 특히, PL-BERT는 문자를 필요로 하지 않으며, 효율적인 훈련과 추론이 가능합니다.
    

TTS 분야의 **자연스러움** 개선을 위한 도전 과제가 여전히 존재합니다.

- 음성 합성을 위한 기술 발전에도 불구하고, 자연스럽고 표현력 있는 음성을 생성하는 것은 여전히 도전적입니다.
    
- 특히 음성의 **억양**과 감정을 포착하는 것은 기존 데이터의 부족으로 인해 어려움이 큽니다.
    
- 이러한 문제를 해결하기 위해 음소 수준의 학습이 필수적입니다.
    

**Ablation Study** 결과를 통해 음소 수준 BERT의 효과성을 확인했습니다.

- LP2G 모델이 제거된 상태에서도 음소 수준 BERT는 기존 StyleTTS 모델보다 높은 성능을 유지했습니다.
    
- 이 연구는 LMLM 전략이 **풍부한** 언어적 표현을 학습하는 데 기여한다고 보여주었습니다.
    
- 결과적으로, 음소 수준 BERT는 다양한 TTS 작업에 긍정적인 영향을 미칠 것으로 판단됩니다.
    

**미래 연구 방향**은 OOD 텍스트 개발에 집중해야 합니다.

- 대부분의 기존 TTS 모델은 In-distribution과 OOD 텍스트 간에 성능 차이를 보였습니다.
    
- 특히, 실제 응용에서 In-distribution의 사용률은 낮기 때문에 OOD에 대한 연구가 필요합니다.
    
- 이 연구에서는 음소 정보를 효과적으로 활용하는 방법을 제안하며, 향후 발전 가능성이 큽니다.
    

## 타임라인

### 1. ️📢음성 합성을 위한 음소 수준 BERT 개선

- 대규모 사전 훈련된 언어 모델은 텍스트-음성 변환(TTS) 모델의 자연스러움을 향상시키는 데 유용하다고 알려져 있다.
    
- 그러나 이러한 모델은 일반적으로 단어 수준 또는 서브 음소 수준에서 훈련되어 음소가 필요한 다운스트림 TTS 작업에 비효율적이다.
    
- 이에 따라 본 연구에서는 음소 수준 BERT(PL-BERT)를 제안하며, 정규 마스크 음소 예측과 함께 해당 그래프 예측을 실시하는 과제를 추가했다.
    
- 주관적 평가 결과, 음소 수준 BERT 인코더가 음성 합성의 자연스러움에 대한 평균 의견 점수(MOS)를 기존 최첨단(StyleTTS) 모델보다 유의미하게 향상시킨 것을 확인했다.
    


  

### 2. 음성 합성에서의 TTS 발전과 BERT 모델 제안

- 음성 합성 기술(TTS)은 최근 몇 년간 큰 발전을 이루었지만, 자연스럽고 표현력 있는 음성을 생성하는 데에는 여전히 도전 과제가 남아있다.
    
- 특히 세부사항으로는 어조와 감정을 포함한 음성의 억양을 효과적으로 포착하는 것이 어려운데, 기존 데이터의 양이 충분하지 않기 때문이다.
    
- BERT 모델은 단어, 문자, 문장 수준에서 TTS 모델의 성능을 개선하는 데 효과적이라는 사실이 입증되었지만, 음소 수준에서는 훈련되지 않았다.
    
- 우리는 문자와 음소 예측을 결합한 음소 수준의 BERT 모델을 제안하여, 기존 모델보다 더 효율적인 성능을 제공하며, 문자 입력 없이도 작동할 수 있게 하였다.
    
- 주관적 평가 결과, 우리의 음소 수준 BERT 모델이 자연스러운 음성의 인식에 있어서 현재의 최첨단 모델인 StyleTTS를 유의미하게 능가하는 것으로 나타났다.
    


  

### 3. 폰음 수준 BERT의 개요

- 폰음 수준 BERT는 **명확한 음성 합성**을 위해 오직 폰음만을 입력으로 사용한다.
    
- 기존의 그래픔 또는 초폰음 표현은 사용하지 않는데, 이는 막대한 어휘 크기로 인해 학습과 추론 속도가 느려질 수 있기 때문이다.
    
- 폰음만의 표현을 사용함으로써, 사전 학습된 인코더는 TTS 시스템의 텍스트 인코더에 즉시 적용 가능하다.
    
- 사전 학습을 위해, 폰음과 그래픔을 쌍으로 얻을 수 있는 어떤 코퍼스에서도 자가 감독 방식으로 학습할 수 있다.
    
- 사전 학습을 위한 목표는 마스크된 폰음 토큰 예측과 폰음-그래픔 예측으로, 이러한 목표는 TTS 작업에서 의미 있는 폰음 수준 언어 표현을 학습하는 데 중요하다.
    


### 4. 🗣️음성 자연스러움을 높이는 새로운 Phoneme-level BERT 제안

- 대규모 사전 학습 언어 모델이 텍스트-음성 변환(TTS) 모델의 자연스러운 발음 패턴을 향상시키는 데 유용한 것으로 나타났으나, 대부분의 모델이 단어 수준이나 하위 음소 수준에서 훈련되어 비효율적이었다.
    
- 이에 따라 음소와 자소 예측을 함께 수행하는 Phoneme-level BERT(PL-BERT)를 제안하며, 주관적 평가에서 PL-BERT 인코더가 최첨단 StyleTTS 모델을 넘어서서 음성 자연스러움 평가 점수를 크게 향상시켰다.
    
- TTS 모델의 훈련에는 수백 시간의 입력이 필요하지만, 대부분의 TTS 데이터셋은 이보다 적은 데이터로 구성되어 음성의 억양과 감정을 학습하는 데 어려움이 있다.
    
- PL-BERT 모델은 단일 음소를 입력으로 사용하여 자소 또는 하위 음소 유닛을 필요로 하지 않으며, 이는 훈련과 추론을 더욱 효율적으로 만든다.
    


### 5. ️📊 Ablation Study 결과 및 분석

- 테이블 3은 LP2G가 제거된 상태에서 훈련할 때 성능이 **약간 감소**하는 것을 보여주지만, 여전히 BERT 없이 기본 StyleTTS 모델보다 높은 CMOS를 유지한다.
    
- LP2G 없이 훈련해도 **사전 훈련된 음소 수준의 BERT**를 사용하면 다운스트림 TTS 작업에 도움이 된다는 것을 나타낸다.
    
- 전부 그래프 음소가 마스킹되는 마스킹 전략 덕분에 LMLM만으로도 **풍부한 언어적 표현**을 학습할 수 있다.
    
- 하지만 LMLM이 제거되었을 경우 CMOS가 급격히 떨어지며, 이는 LP2G만으로는 입력 음소 정보를 보존할 수 없음을 의미한다.
    
- LP2G가 훈련 목표에서 제거되면 P2G 예측 정확도가 **급격히 감소**하며, 이는 LMLM이 전체 단어 마스킹으로도 단어 수준 언어 표현을 보장하지 않음을 나타낸다.
    


  

### 6. ️📊음소 수준 BERT 모델 제안 및 향후 연구 방향

- 본 연구에서는 음소 수준의 BERT 모델을 제안하여, **자연스러움**과 **운율**을 개선하는 문맥화된 임베딩을 생성하는 언어 모델을 개발하였다.
    
- 우리 모델은 이전 연구와 달리 음소만 입력으로 사용하여, 학습과 추론 시 필요한 자원을 크게 줄였다.
    
- 모델이 기존 스타일 TTS 모델보다 **상당히 우수한 성능**을 보였으며, OOD 텍스트에 대한 사전 훈련 전략이 MP-BERT보다 더 효과적임을 입증하였다.
    
- 많은 기존 TTS 모델에서 In-distribution과 OOD 텍스트 간에 성능 차이를 확인하였고, 실제 응용에서 In-distribution 텍스트는 거의 사용되지 않으므로 향후 연구는 OOD 텍스트 개발에 더욱 집중해야 한다.
    
- 이 연구의 진행 중 모델 품질에 대한 피드백을 제공한 가빈 미슐러에게 감사드리며, 이 연구는 NIH-NIDCD 및 마리 조제와 헨리 R. 크래비스의 지원을 받았다.
    



### 7. 참고 문헌

- [1] Tan, X., Chen, J., Liu, H. 등, “Natural speech: End-to-end text to speech synthesis with human-level quality,” arXiv preprint arXiv:2205.04421, 2022.
    
- [2] Tan, X., Qin, T., Soong, F., Liu, T.-Y., “A survey on neural speech synthesis,” arXiv preprint arXiv:2106.15561, 2021.
    
- [3] Li, Y.A., Han, C., Mesgarani, N., “Styletts: A style-based generative model for natural and diverse text-to-speech synthesis,” arXiv preprint arXiv:2205.15439, 2022.
    
- [4] Kenter, T., Sharma, M.K., Clark, R., “Improving prosody of rnn-based english text-to-speech synthesis by incorporating a bert model,” 2020.
    
- [5] Xiao, Y., He, L., Ming, H., Soong, F.K., “Improving prosody with linguistic and bert derived features in multi-speaker based mandarin chinese neural tts,” ICASSP 2020, pp. 6704–6708.
    

