---
title: 카프카 기반 리그오브레전드 챔피언 추천 서비스
created: 2024-08-18 17:30
---



흥미로운 내용 3가지 :

- 리그오브레전드 개인화 챔피언 추천 서비스는 유저의 게임 스타일을 반영해 맞춤형 추천을 제공하여 플레이 흥미를 높이는 것을 목표로 한다.  
- 데이터 파이프라인, 클라우드 기반 관리 및 ML 모델링 기술이 서비스의 핵심 요소로, 이를 통해 유저에게 실시간으로 유용한 정보를 전달한다.  
- 팀 구성원들이 데이터 엔지니어링, 웹 서비스 개발 및 ML Ops를 담당하며, 지속적으로 서비스 개선과 확장을 위해 노력하고 있다.  




이 발표는 리그오브레전드에 특화된 개인화된 챔피언 추천 서비스 개발에 대한 내용을 다루고 있습니다. 개발 팀은 데이터 파이프라인, 클라우드 기반 데이터 관리, ML 모델링 기술을 활용하여 유저 맞춤형 서비스를 구현하였습니다. 특히, 게임 스타일에 맞춘 추천 시스템이 유저의 흥미를 높이고, 플레이의 폭을 확장하는 데 도움을 줄 수 있다는 점을 강조합니다. 이 영상을 통해 데이터 엔지니어링과 ML 기술을 활용한 실질적인 서비스 개발 과정을 배우고, 실제 적용 사례를 통해 영감을 얻을 수 있습니다.

# 핵심주제

리그 오브 레전드의 **개인화된** 챔피언 추천 서비스는 유저의 **게임 스타일**을 반영합니다.

- 기존 추천 시스템이 **일반적인 기준**으로만 작동했지만, 유저의 성향은 다양하므로 맞춤형 접근이 필요합니다.
    
- 이 서비스는 승리에 꼭 필요한 데이터를 활용하며, 유저의 **티어 상승**에 긍정적인 영향을 미칠 수 있습니다.
    

'데이터 드래곤'을 활용한 **게임 데이터 모델링**이 핵심으로 자리 잡았습니다.

- JSON 파일을 기반으로 챔피언, 아이템, 게임 요소를 **중앙 집중화** 하여 효율적으로 관리합니다.
    
- 패치 노트 데이터는 정기적으로 업데이트되어 게임의 변화에 즉각적으로 대응할 수 있게 돕습니다.
    

**파이프라인 아키텍처**와 데이터 처리 과정이 체계적으로 설계되었습니다.

- ETL 과정에 기초하여 AWS 등 클라우드 기술을 통해 데이터 흐름을 원활하게 처리합니다.
    
- 크롤링된 데이터는 정제 과정을 거쳐 효율적으로 저장되며, 분석을 위해 다양한 형식으로 변환됩니다.
    

**ML 모델링**을 통해 유저 데이터 분석 및 예측이 가능합니다.

- 트리 기반 모델을 활용하여 데이터를 **비선형 관계**로 잘 포착하고, 빠르게 학습하며 결과를 도출합니다.
    
- 플로우 기반 환경과 AWS S3를 통해 기존 데이터의 관리 및 업데이트가 실시간으로 이루어집니다.
    

프로젝트가 **완성된 데이터 파이프라인**으로 큰 성과를 거두었습니다.

- 자동화와 스케줄링을 통해 데이터 수집과 정제가 효율적으로 이루어졌고, 카프카를 활용하여 데이터 처리의 **핵심 내용을** 성공적으로 구현했습니다.
    
- 그러나 웹 페이지 개발 및 대규모 서비스 관리에서 아쉬움이 남아 개선의 필요성을 느끼고 있습니다.
    

# 타임라인

## 1. 🎉 20회 진 컨퍼런스 마지막 발표: 리그오브레전드 챔피언 추천 서비스

![](assets/8edb4a5343287a6d184f94e154dac3d2_MD5.jpg)

- LP 팀은 "라피스"라는 뜻이며, 롤 프로젝트의 줄임말입니다. 그리고 이 프로젝트는 리그오브레전드의 개인화된 챔피언 추천 서비스를 목표로 하고 있습니다.
    
- 목차는 데이터 파이프라인, 클라우드 기반 데이터 관리, ML 모델링 기술로 구성되어 있습니다. 이는 서비스의 전반적인 구성을 설명합니다.
    
- 팀 구성은 4명으로 이루어져 있습니다. 선희 님과 발표자는 데이터 엔지니어링과 웹 서비스 개발을, 혜정 님이 ML 모델링과 ML Ops을, 그리고 수미 님이 뉴스레터 서비스 개발을 담당했습니다.
    
- 이 프로젝트는 유저 맞춤형 서비스를 제공하여 유저의 흥미를 높이고 플레이의 폭을 확장하는 데 초점을 맞추고 있습니다.
    
- 데이터 파이프라인과 클라우드 데이터 관리 및 ML 모델링 기술이 이 서비스의 핵심 요소입니다.
    

  

## 2. ️🎮리그 오브 레전드를 위한 맞춤형 챔피언 추천 서비스

![](assets/441d24097fbe30925e3efb0cd13fa214_MD5.jpg)

- 저희 **LP 프로젝트**는 리그 오브 레전드의 공식 게임 업데이트 정보를 바탕으로 유저 맞춤형 챔피언을 추천하는 서비스입니다.
    
- 기존 서비스들은 일반적인 기준으로 추천했지만, 유저의 **게임 스타일**은 각각 다르므로, 이를 반영한 개인화된 추천 서비스가 필요합니다.
    
- 예를 들어, 원거리 챔피언 선호하는 유저에게는 통계적으로 인기 있는 근거리 챔피언을 추천하는 것은 유용하지 않으므로, 유저 데이터에 기반한 추천이 중요합니다.
    
- 이러한 개인화된 추천 서비스는 유저의 게임 흥미를 높이고, 실력 지표인 **티어 상승**에도 긍정적인 영향을 미칠 수 있습니다.
    
- 저희는 라이어 API 데이터를 통해 유저 개인별 정보 및 게임 데이터를 추출하고, 승리에 직접적인 연관성을 가진 데이터를 활용했습니다.
    

  

## 3. 게임 데이터 모델링과 패치 노트 관리

![](assets/d1ce4521c266b71e7b56e031f3f92818_MD5.jpg)

- 피처를 선정하여 모델링을 활용할 수 있었으며, '데이터 드래곤'은 라이엇이 제공하는 JSON 파일로, 중앙 집중화를 목적으로 챔피언, 아이템, 게임 요소를 관리한다.
    
- 이 JSON 파일은 버전 관리가 되어 있어, 게임이 업데이트될 때마다 신화서 업데이트된다.
    
- 챔피언 추천 기능이 있어 챔피언 데이터의 업데이트 작업이 중요하며, 이를 위해 167개 챔피언에 대한 데이터를 JSON 키-값 형식으로 정리한 데이터베이스를 구축했다.
    
- 마지막으로, 패치 노트 데이터는 2주 또는 한 달 간격으로 업데이트되어, 챔피언의 기본 능력치와 스킬, 아이템 등이 조정되며, 업데이트가 있을 경우 자동으로 크롤링하여 데이터베이스에 저장한다.
    

  

## 4. 파이프라인 아키텍처와 데이터 처리 과정

![](2bfd13dadc67f56efd35b14873ec13e4_MD5.jpg)

- 파이프라인 아키텍처는 ETL 과정에 맞춰 구성되어 있으며, 라이언 API 데이터는 상업적 활용 동의 후 게임 매치 데이터 요청이 가능하다.
    
- 최신 패치노트 업데이트를 자동으로 처리하기 위해 AWS 이벤트 브릿지와 람다를 활용하여 스케줄링을 통한 프로세스를 구축했다.
    
- 크롤링된 데이터는 정제 과정을 거쳐 S3와 MySQL DB에 저장되며, 널링된 패치노트를 구조화된 형태로 저장하였다.
    
- 저장된 데이터는 JSON 형식으로 변환되며, 분석 효율성을 위해 CSV 포맷으로도 변환하여 S3에 저장한다.
    
- 데이터베이스 파이프라인에서 활용할 데이터를 미리 구상하고 MySQL TV 내부에 테이블을 마련해 두었다.
    

  

## 5. 서비스 설계를 위한 멀티모듈 아키텍처 소개

![](assets/cd4e856824212de0e81f4211b6a28766_MD5.jpg)

- 서비스의 요구 사항에 맞춰 **DVL**을 설계하였고, 주요 테이블링 챔피언을 기준으로 챔피언 버전과 패치노트 버전, 구동 요구 및 구독자 관리 등을 포함했습니다.
    
- 웹 서비스는 백엔드를 코틀린과 스프링부트로 모듈 역할 분리를 통해 멀티모듈 아키텍처로 구축했으며, 이는 기능 확장과 유지 보수를 효과적으로 관리하게 해줍니다.
    
- 모듈 구조는 도메인 모듈과 스토리지 모듈로 나뉘며, 스토리지 모듈은 데이터베이스 접근을 담당하고 도메인 모듈은 서비스를 포함합니다.
    
- 데이터 엔지니어링 기술 및 클라우드 아키텍처를 활용하여, ETL 아키텍처와 함께 전체 데이터 파이프라인을 구성했습니다.
    
- 아파치 카프카는 대규모 이벤트 스트리밍 플랫폼으로, 실시간 데이터를 처리하고 높은 처리량과 확장성을 제공합니다.
    

  

## 6. 카프카를 통한 데이터 흐름 관리 및 서비스 구조

![](assets/fbc15824b95cd07e4b13ba4f99d54c4f_MD5.jpg)

- 저희 서비스에서는 **API**, **배치**, **ML 서버**를 연결하여 데이터 흐름을 **메시지**를 통해 관리하고 있습니다.
    
- 카프카의 주요 구성 요소는 생산자, 소비자, 브로커로 구성되며, 각각의 역할은 데이터 메시지를 전달하고 저장하며 순서를 관리하는 것입니다.
    
- 내부 데이터 흐름은 배치 서버가 API를 통해 전적 데이터를 로컬에 저장하고, 머신러닝을 통해 필요한 데이터를 전처리하여 카프카 브로커로 전송합니다.
    
- 이러한 과정에서 ML 서버는 새로운 데이터로 모델을 갱신하고, 업데이트된 사용자 전적 평가 데이터는 다시 몽고DB에 적재됩니다.
    
- 두 번째 흐름은 DB 변경 사항을 감지해 카프카 커넥터를 이용해 메시지를 발행하고, API 서버를 통해 구독자에게 뉴스레터를 발송하는 방식으로 이루어집니다.
    

  

## 7. 분산 아키텍처와 ML 모델링 환경 설명

![](assets/494441255da458e2e1c4b29dd27824de_MD5.jpg)

- 스터 생성 및 발성을 통해 백그라운드 비동기를 처리하고, 카프카의 대규모 처리 기능을 활용하여 **확장성 있는 분산 아키텍처**를 구축할 수 있다.
    
- ML 모델링 파트의 아키텍처에서는 빨간색으로 표시된 프라이머리 ML 서버가 카프카 브로커를 구독하며, 유저 데이터로 모델 인퍼런스를 진행해 LP 티어를 계산하고 그 결과를 몽고DB 컬렉션에 인서트한다.
    
- 사용한 모델 종류는 **트리 기반 모델**로, 이는 데이터의 비선형 관계를 잘 포착하고, 계산 효율성이 뛰어나 큰 데이터에 대해서도 빠르게 학습할 수 있다.
    
- LP 서비스의 실험 환경은 다양한 트리 기반 모델을 하이퍼 파라미터 튜닝하며 실험할 수 있도록 구성되었으며, 실시간 업데이트되는 유적 게임 데이터에 맞춰 짧은 주기로 실험이 필요하다.
    
- 문제를 해결하기 위해 플로우 기반의 옵스 환경을 구축하고, 모델을 AWS S3에 저장한 후 API 형태로 배포하여 메타데이터를 관리하였다.
    

  

## 8. 프로젝트 회고 및 개선점 공유

![](assets/67189a0e9313fa2186121293cc329c43_MD5.jpg)

- 22에 **ML 플로우 UI**를 띄워 실험 정보를 조회하며 ML 모델링을 진행했고, **완성된 데이터 파이프라인 아키텍처**에 상당히 만족했다.
    
- 데이터 수집 및 정제 자동화를 스케줄링하며, 카프카를 통해 서버가 데이터를 처리하는 방식까지 핵심 내용을 모두 구현했다.
    
- 프로젝트하면서 로직 빌드 과정에서 많은 트러블이 발생해 역할 분리에 대해 고민이 많아졌지만, 개인적으로는 제가 **좋아하는 주제**로 프로젝트를 진행하게 되어 큰 위안이 되었다.
    
- 개선점으로는 **웹페이지 개발**의 부족함과 대규모 서비스로서의 로인 관리 미비점이 아쉬웠으며, 특히 크롤링 알림 서비스 구현 필요성을 느꼈다.
    
- 마지막으로 팀 이름인 '라스트 피스'는 인기 상품이 품절된 의미를 담아 정해졌으며, 이 프로젝트가 많은 사람들이 주목받기를 바란다.